{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4a14fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install yfinance scipy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c050f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import t\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae58654b",
   "metadata": {},
   "source": [
    "Загрузчик данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427b2164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sp500(start=\"2020-01-01\", end=\"2025-12-31\"):\n",
    "    \"\"\"\n",
    "    Загрузка данных S&P 500\n",
    "    \n",
    "    Args:\n",
    "        start: начальная дата\n",
    "        end: конечная дата\n",
    "    \n",
    "    Returns:\n",
    "        Series с ценами закрытия\n",
    "    \"\"\"\n",
    "    data = yf.download(\"^GSPC\", start=start, end=end, progress=False)\n",
    "    \n",
    "    if 'Adj Close' in data.columns:\n",
    "        return data[\"Adj Close\"]\n",
    "    elif 'Close' in data.columns:\n",
    "        return data[\"Close\"]\n",
    "    else:\n",
    "        price_columns = ['Close', 'Adj Close', 'Open', 'High', 'Low']\n",
    "        for col in price_columns:\n",
    "            if col in data.columns:\n",
    "                print(f\"Используется {col} вместо Adj Close\")\n",
    "                return data[col]\n",
    "        \n",
    "        print(f\"Используется {data.columns[0]}\")\n",
    "        return data[data.columns[0]]\n",
    "\n",
    "def compute_log_returns(prices: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Расчет логарифмических доходностей\n",
    "    \n",
    "    Args:\n",
    "        prices: ряд цен\n",
    "    \n",
    "    Returns:\n",
    "        ряд логарифмических доходностей\n",
    "    \"\"\"\n",
    "    return np.log(prices / prices.shift(1)).dropna()\n",
    "\n",
    "def train_test_split(data, split_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Разделение данных на обучающую и тестовую выборки\n",
    "    \n",
    "    Args:\n",
    "        data: входные данные\n",
    "        split_ratio: доля обучающей выборки\n",
    "    \n",
    "    Returns:\n",
    "        train, test - numpy массивы\n",
    "    \"\"\"\n",
    "    split_index = int(len(data) * split_ratio)\n",
    "    train = data[:split_index]\n",
    "    test = data[split_index:]\n",
    "    return train.values, test.values\n",
    "\n",
    "# Тестовая функция \n",
    "def test_data_loader():\n",
    "    \"\"\"Тест загрузчика данных\"\"\"\n",
    "    print(\"Тестирование загрузчика данных...\")\n",
    "    try:\n",
    "        prices = load_sp500(start=\"2023-01-01\", end=\"2024-01-01\")\n",
    "        returns = compute_log_returns(prices)\n",
    "        \n",
    "        n_days = len(prices)\n",
    "        min_price = float(prices.min())\n",
    "        max_price = float(prices.max())\n",
    "        mean_return = float(returns.mean())\n",
    "        std_return = float(returns.std())\n",
    "        \n",
    "        print(f\"Успешно загружено {n_days} дней данных\")\n",
    "        print(f\"Диапазон цен: {min_price:.2f} - {max_price:.2f}\")\n",
    "        print(f\"Доходности: mean={mean_return:.6f}, std={std_return:.6f}\")\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка: {e}\")\n",
    "        return False\n",
    "\n",
    "# Запускаем тест\n",
    "test_data_loader()\n",
    "\n",
    "print(\"\\ndata_loader.py загружен\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ecf7cd",
   "metadata": {},
   "source": [
    "Диффузионная модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27431c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionModel:\n",
    "    def __init__(self, timesteps=1000, schedule_type='cosine'):\n",
    "        \"\"\"\n",
    "        Диффузионная модель с различными типами графиков шума\n",
    "        \n",
    "        Args:\n",
    "            timesteps: количество шагов диффузии\n",
    "            schedule_type: тип графика шума ('linear', 'cosine', 'quadratic')\n",
    "        \"\"\"\n",
    "        self.timesteps = timesteps\n",
    "        self.schedule_type = schedule_type\n",
    "        \n",
    "        if schedule_type == 'linear':\n",
    "            self.beta = torch.linspace(1e-4, 0.02, timesteps)\n",
    "        elif schedule_type == 'cosine':\n",
    "            self.beta = self._cosine_beta_schedule(timesteps)\n",
    "        elif schedule_type == 'quadratic':\n",
    "            self.beta = torch.linspace(1e-4, 0.02, timesteps) ** 2\n",
    "        else:\n",
    "            raise ValueError(f\"Неизвестный тип графика: {schedule_type}\")\n",
    "        \n",
    "        self.alpha = 1.0 - self.beta\n",
    "        self.alpha_hat = torch.cumprod(self.alpha, dim=0)\n",
    "        \n",
    "    def _cosine_beta_schedule(self, timesteps, s=0.008):\n",
    "        \"\"\"\n",
    "        Косинусный график шума из работы Nichol & Dhariwal (2021)\n",
    "        \"\"\"\n",
    "        steps = timesteps + 1\n",
    "        x = torch.linspace(0, timesteps, steps)\n",
    "        alphas_cumprod = torch.cos(((x / timesteps) + s) / (1 + s) * torch.pi * 0.5) ** 2\n",
    "        alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "        betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "        return torch.clip(betas, 0.0001, 0.9999)\n",
    "    \n",
    "    def add_noise(self, x, t):\n",
    "        \"\"\"\n",
    "        Добавление шума на временном шаге t\n",
    "        \"\"\"\n",
    "        noise = torch.randn_like(x)\n",
    "        alpha_hat_t = self.alpha_hat[t].reshape(-1, 1)\n",
    "        noisy_x = torch.sqrt(alpha_hat_t) * x + torch.sqrt(1 - alpha_hat_t) * noise\n",
    "        return noisy_x, noise\n",
    "    \n",
    "    def sample_forward(self, x0, t):\n",
    "        \"\"\"\n",
    "        Сэмплирование из прямого процесса\n",
    "        \"\"\"\n",
    "        noise = torch.randn_like(x0)\n",
    "        alpha_hat_t = self.alpha_hat[t]\n",
    "        return torch.sqrt(alpha_hat_t) * x0 + torch.sqrt(1 - alpha_hat_t) * noise\n",
    "\n",
    "print(\"diffusion_model.py загружен\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c5b415",
   "metadata": {},
   "source": [
    "Нейронная сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc97be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(dim, dim)\n",
    "        self.linear2 = nn.Linear(dim, dim)\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.norm1(x)\n",
    "        x = F.gelu(self.linear1(x))\n",
    "        x = self.norm2(x)\n",
    "        x = self.linear2(x)\n",
    "        return x + residual\n",
    "\n",
    "class NoisePredictor(nn.Module):\n",
    "    def __init__(self, input_dim=1, hidden_dim=256, num_blocks=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_proj = nn.Linear(input_dim, hidden_dim)\n",
    "        \n",
    "        # Residual blocks\n",
    "        self.blocks = nn.ModuleList([\n",
    "            ResidualBlock(hidden_dim) for _ in range(num_blocks)\n",
    "        ])\n",
    "        \n",
    "        # Time embedding (для учета временного шага)\n",
    "        self.time_embed = nn.Sequential(\n",
    "            nn.Linear(1, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        self.output_proj = nn.Linear(hidden_dim, input_dim)\n",
    "        \n",
    "        # Инициализация весов\n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def forward(self, x, t=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: входные данные [batch_size, input_dim]\n",
    "            t: временной шаг [batch_size, 1] (опционально)\n",
    "        \"\"\"\n",
    "        h = self.input_proj(x)\n",
    "        \n",
    "        if t is not None:\n",
    "            t_emb = self.time_embed(t.float())\n",
    "            h = h + t_emb\n",
    "        \n",
    "        for block in self.blocks:\n",
    "            h = block(h)\n",
    "        \n",
    "        return self.output_proj(h)\n",
    "\n",
    "print(\"network.py загружен\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a3c6d1",
   "metadata": {},
   "source": [
    "Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b954bd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_improved(data, epochs=50, batch_size=64, lr=1e-3, \n",
    "                        timesteps=1000, device=None):\n",
    "    \"\"\"\n",
    "    Улучшенная функция обучения с валидацией и визуализацией\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Используется устройство: {device}\")\n",
    "    print(f\"Параметры: epochs={epochs}, batch_size={batch_size}, lr={lr}, timesteps={timesteps}\")\n",
    "    \n",
    "    # Разделение на train/val\n",
    "    split = int(0.8 * len(data))\n",
    "    train_data = data[:split]\n",
    "    val_data = data[split:]\n",
    "    print(f\"Данные: train={len(train_data)}, val={len(val_data)}\")\n",
    "    \n",
    "    # Подготовка данных\n",
    "    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1)\n",
    "    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1)\n",
    "    \n",
    "    train_dataset = TensorDataset(train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Инициализация моделей\n",
    "    model = NoisePredictor(input_dim=1, hidden_dim=128).to(device)\n",
    "    diffusion = DiffusionModel(timesteps=timesteps, schedule_type='cosine')\n",
    "    \n",
    "    # Оптимизатор с планировщиком learning rate (УБРАЛИ verbose)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=10\n",
    "    )\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Для отслеживания истории обучения\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    print(\"\\nНачало обучения на 50 эпохах...\")\n",
    "    print()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        epoch_train_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            x = batch[0].to(device)\n",
    "            \n",
    "            # Случайные временные шаги для каждого элемента в батче\n",
    "            t = torch.randint(0, diffusion.timesteps, (x.shape[0],), device=device)\n",
    "            \n",
    "            # Добавление шума\n",
    "            noisy_x, noise = diffusion.add_noise(x, t)\n",
    "            \n",
    "            # Предсказание шума\n",
    "            predicted_noise = model(noisy_x)\n",
    "            \n",
    "            # Вычисление потерь\n",
    "            loss = criterion(predicted_noise, noise)\n",
    "            \n",
    "            # Обратное распространение\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            # Градиентный клиппинг для стабильности\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_train_loss += loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        avg_train_loss = epoch_train_loss / num_batches\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_tensor_device = val_tensor.to(device)\n",
    "            t_val = torch.randint(0, diffusion.timesteps, (val_tensor_device.shape[0],), device=device)\n",
    "            noisy_val, noise_val = diffusion.add_noise(val_tensor_device, t_val)\n",
    "            pred_val = model(noisy_val)\n",
    "            val_loss = criterion(pred_val, noise_val).item()\n",
    "            val_losses.append(val_loss)\n",
    "        \n",
    "        # Обновление learning rate\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Сохранение лучшей модели\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        \n",
    "        # Вывод прогресса\n",
    "        if (epoch + 1) % 5 == 0:  # каждые 5 эпох\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            print(f\"Epoch {epoch+1:3d}/{epochs}, Train Loss: {avg_train_loss:.6f}, \"\n",
    "                  f\"Val Loss: {val_loss:.6f}, LR: {current_lr:.2e}\")\n",
    "    \n",
    "\n",
    "    print(f\"Обучение завершено!\")\n",
    "    print(f\"Лучшая validation loss: {best_val_loss:.6f}\")\n",
    "    \n",
    "    # Визуализация процесса обучения\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # График loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train Loss', alpha=0.7)\n",
    "    plt.plot(val_losses, label='Validation Loss', alpha=0.7)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Процесс обучения (50 эпох)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # График предсказаний vs реальность\n",
    "    plt.subplot(1, 2, 2)\n",
    "    with torch.no_grad():\n",
    "        sample_size = min(100, len(val_tensor_device))\n",
    "        x_sample = val_tensor_device[:sample_size]\n",
    "        t_sample = torch.randint(0, diffusion.timesteps, (sample_size,), device=device)\n",
    "        noisy_sample, noise_sample = diffusion.add_noise(x_sample, t_sample)\n",
    "        pred_sample = model(noisy_sample)\n",
    "        \n",
    "        plt.scatter(noise_sample.cpu().numpy(), pred_sample.cpu().numpy(), alpha=0.5)\n",
    "        plt.plot([-3, 3], [-3, 3], 'r--', alpha=0.7, label='Идеальное совпадение')\n",
    "        plt.xlabel('Реальный шум')\n",
    "        plt.ylabel('Предсказанный шум')\n",
    "        plt.title('Качество предсказаний')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_results.png', dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "    return model, train_losses, val_losses\n",
    "\n",
    "print(\"train.py загружен (исправленная версия)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7207f607",
   "metadata": {},
   "source": [
    "ЗАПУСК ОБУЧЕНИЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b87813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерируем данные с финансовыми свойствами\n",
    "np.random.seed(42)\n",
    "n_samples = 10000  # больше данных для лучшего обучения\n",
    "\n",
    "# Используем t-распределение с тяжелыми хвостами\n",
    "returns = t.rvs(df=3, size=n_samples) * 0.01\n",
    "\n",
    "print(f\"\\n Статистики данных:\")\n",
    "print(f\"  Samples: {n_samples}\")\n",
    "print(f\"  Mean:    {np.mean(returns):.6f}\")\n",
    "print(f\"  Std:     {np.std(returns):.6f}\")\n",
    "print(f\"  Skew:    {np.mean((returns - np.mean(returns))**3) / np.std(returns)**3:.3f}\")\n",
    "print(f\"  Kurt:    {np.mean((returns - np.mean(returns))**4) / np.std(returns)**4:.3f}\")\n",
    "print()\n",
    "\n",
    "# Обучаем модель на 50 эпохах\n",
    "model, train_losses, val_losses = train_model_improved(\n",
    "    data=returns,\n",
    "    epochs=50,  \n",
    "    batch_size=128,\n",
    "    lr=1e-3,\n",
    "    timesteps=1000\n",
    ")\n",
    "\n",
    "print(\"ИТОГОВЫЕ РЕЗУЛЬТАТЫ:\")\n",
    "print(f\"Начальный loss:  {train_losses[0]:.6f}\")\n",
    "print(f\"Конечный loss:   {train_losses[-1]:.6f}\")\n",
    "print(f\"Улучшение:       {(1 - train_losses[-1]/train_losses[0])*100:.1f}%\")\n",
    "print(f\"Лучший val loss: {min(val_losses):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8045808f",
   "metadata": {},
   "source": [
    "Детальный анализ результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0f9900",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = next(model.parameters()).device  # определяем device из модели\n",
    "print(f\"Используется устройство: {device}\")\n",
    "\n",
    "# Создаем diffusion объект с теми же параметрами\n",
    "diffusion = DiffusionModel(timesteps=1000, schedule_type='cosine')\n",
    "diffusion.alpha_hat = diffusion.alpha_hat.to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Генерируем тестовые данные\n",
    "    test_size = 1000\n",
    "    # Используем данные из returns (они уже есть в памяти)\n",
    "    test_data = torch.tensor(returns[-test_size:], dtype=torch.float32).unsqueeze(1).to(device)\n",
    "    \n",
    "    # Добавляем шум и предсказываем\n",
    "    t_test = torch.randint(0, diffusion.timesteps, (test_size,), device=device)\n",
    "    noisy_test, noise_test = diffusion.add_noise(test_data, t_test)\n",
    "    pred_test = model(noisy_test)\n",
    "    \n",
    "    # Вычисляем ошибки\n",
    "    errors = (pred_test.cpu().numpy() - noise_test.cpu().numpy()).flatten()\n",
    "    real_noise = noise_test.cpu().numpy().flatten()\n",
    "    pred_noise = pred_test.cpu().numpy().flatten()\n",
    "\n",
    "# Создаем графики\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# 1. История обучения\n",
    "axes[0,0].plot(train_losses, label='Train', alpha=0.7)\n",
    "axes[0,0].plot(val_losses, label='Validation', alpha=0.7)\n",
    "axes[0,0].axhline(y=0.13, color='r', linestyle='--', alpha=0.5, label='Целевой уровень')\n",
    "axes[0,0].set_xlabel('Эпоха')\n",
    "axes[0,0].set_ylabel('Loss')\n",
    "axes[0,0].set_title('История обучения')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Предсказания vs реальность\n",
    "axes[0,1].scatter(real_noise, pred_noise, alpha=0.3, s=10)\n",
    "axes[0,1].plot([-3,3], [-3,3], 'r--', alpha=0.7, label='Идеал')\n",
    "axes[0,1].set_xlabel('Реальный шум')\n",
    "axes[0,1].set_ylabel('Предсказанный шум')\n",
    "axes[0,1].set_title('Качество предсказаний')\n",
    "axes[0,1].legend()\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Распределение ошибок\n",
    "axes[0,2].hist(errors, bins=50, alpha=0.7, density=True)\n",
    "axes[0,2].set_xlabel('Ошибка предсказания')\n",
    "axes[0,2].set_ylabel('Плотность')\n",
    "axes[0,2].set_title('Распределение ошибок')\n",
    "axes[0,2].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Q-Q plot ошибок\n",
    "stats.probplot(errors, dist=\"norm\", plot=axes[1,0])\n",
    "axes[1,0].set_title('Q-Q plot ошибок')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Сравнение распределений\n",
    "axes[1,1].hist(real_noise, bins=50, alpha=0.5, label='Реальный', density=True)\n",
    "axes[1,1].hist(pred_noise, bins=50, alpha=0.5, label='Предсказанный', density=True)\n",
    "axes[1,1].set_xlabel('Значение')\n",
    "axes[1,1].set_ylabel('Плотность')\n",
    "axes[1,1].set_title('Сравнение распределений')\n",
    "axes[1,1].legend()\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Метрики\n",
    "axes[1,2].axis('off')\n",
    "metrics_text = f\"\"\"\n",
    "Итоговые метрики:\n",
    "━━━━━━━━━━━━━━━━━\n",
    "Train Loss:  {train_losses[-1]:.4f}\n",
    "Val Loss:    {val_losses[-1]:.4f}\n",
    "Best Val:    {min(val_losses):.4f}\n",
    "\n",
    "Статистика ошибок:\n",
    "Среднее:     {np.mean(errors):.4f}\n",
    "Std:         {np.std(errors):.4f}\n",
    "Skew:        {stats.skew(errors):.3f}\n",
    "Kurtosis:    {stats.kurtosis(errors):.3f}\n",
    "\n",
    "Корреляция:  {np.corrcoef(real_noise, pred_noise)[0,1]:.3f}\n",
    "MSE:         {np.mean(errors**2):.4f}\n",
    "MAE:         {np.mean(np.abs(errors)):.4f}\n",
    "\"\"\"\n",
    "axes[1,2].text(0.1, 0.5, metrics_text, fontsize=12, verticalalignment='center')\n",
    "axes[1,2].set_xlim(0, 1)\n",
    "axes[1,2].set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('detailed_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"График сохранен как 'detailed_analysis.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c9e83b",
   "metadata": {},
   "source": [
    "Тест на реальных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d369b24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем данные\n",
    "prices = load_sp500(start=\"2020-01-01\", end=\"2024-01-01\")\n",
    "returns = compute_log_returns(prices)\n",
    "\n",
    "# Конвертируем в обычные числа\n",
    "n_days = len(returns)\n",
    "mean_ret = float(returns.mean())\n",
    "std_ret = float(returns.std())\n",
    "min_ret = float(returns.min())\n",
    "max_ret = float(returns.max())\n",
    "skew_ret = float(returns.skew())\n",
    "kurt_ret = float(returns.kurtosis())\n",
    "\n",
    "print(f\"\\nДанные загружены:\")\n",
    "print(f\"  Период: 2020-2024\")\n",
    "print(f\"  Дней: {n_days}\")\n",
    "print(f\"\\nСтатистика доходностей:\")\n",
    "print(f\"  Среднее:  {mean_ret:.6f}\")\n",
    "print(f\"  Стд.откл.: {std_ret:.6f}\")\n",
    "print(f\"  Минимум:   {min_ret:.6f}\")\n",
    "print(f\"  Максимум:  {max_ret:.6f}\")\n",
    "print(f\"  Асимметрия: {skew_ret:.3f}\")\n",
    "print(f\"  Эксцесс:    {kurt_ret:.3f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(returns.index, returns.values, alpha=0.7)\n",
    "plt.title('Доходности S&P 500')\n",
    "plt.xlabel('Дата')\n",
    "plt.ylabel('Доходность')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(returns.values, bins=50, alpha=0.7, edgecolor='black')\n",
    "plt.title('Распределение доходностей')\n",
    "plt.xlabel('Доходность')\n",
    "plt.ylabel('Частота')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5023e5ab",
   "metadata": {},
   "source": [
    "Сравнение реальных и синтетических данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50971e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реальные данные\n",
    "real_stats = {\n",
    "    'Mean': 0.000379,\n",
    "    'Std': 0.014561,\n",
    "    'Skew': -0.783,\n",
    "    'Kurtosis': 12.801,\n",
    "    'Min': -0.127652,\n",
    "    'Max': 0.089683\n",
    "}\n",
    "\n",
    "# Ваши синтетические данные из предыдущего обучения\n",
    "synth_stats = {\n",
    "    'Mean': -0.000013,\n",
    "    'Std': 0.016606,\n",
    "    'Skew': 0.257,\n",
    "    'Kurtosis': 23.517,\n",
    "    'Min': -0.089,\n",
    "    'Max': 0.087\n",
    "}\n",
    "\n",
    "print(f\"\\n{'Метрика':<15} {'Реальные':<15} {'Синтетика':<15} {'Разница':<15} {'Оценка':<15}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "metrics = ['Mean', 'Std', 'Skew', 'Kurtosis', 'Min', 'Max']\n",
    "for metric in metrics:\n",
    "    real = real_stats[metric]\n",
    "    synth = synth_stats[metric]\n",
    "    diff = abs(real - synth)\n",
    "    \n",
    "    if metric == 'Mean':\n",
    "        оценка = \"Отлично\" if diff < 0.001 else \"Приемлемо\"\n",
    "    elif metric == 'Std':\n",
    "        оценка = \"Хорошо\" if diff < 0.003 else \"Можно улучшить\"\n",
    "    elif metric == 'Skew':\n",
    "        оценка = \"Разное направление\" if (real * synth) < 0 else \"Похоже\"\n",
    "    elif metric == 'Kurtosis':\n",
    "        оценка = \"Оба тяжелые\" if diff < 15 else \"Синтетика тяжелее\"\n",
    "    else:\n",
    "        оценка = \"Отличаются\" if diff > 0.03 else \"Похожи\"\n",
    "    \n",
    "    print(f\"{metric:<15} {real:>8.6f}      {synth:>8.6f}      {diff:>8.6f}      {оценка}\")\n",
    "\n",
    "# Визуализация сравнения \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Создаем фигуру с 2x2 subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Сравнение распределений (гистограммы)\n",
    "axes[0,0].hist(returns.values, bins=50, alpha=0.5, label='Реальные S&P 500', \n",
    "               density=True, color='blue', edgecolor='black')\n",
    "# Генерируем синтетику для сравнения\n",
    "synth_sample = np.random.normal(synth_stats['Mean'], synth_stats['Std'], 10000)\n",
    "axes[0,0].hist(synth_sample, bins=50, alpha=0.5, label='Синтетические', \n",
    "               density=True, color='red', edgecolor='black')\n",
    "axes[0,0].set_xlabel('Доходность')\n",
    "axes[0,0].set_ylabel('Плотность')\n",
    "axes[0,0].set_title('Сравнение распределений доходностей')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Временной ряд реальных доходностей\n",
    "axes[0,1].plot(returns.index, returns.values, alpha=0.7, color='blue', linewidth=0.5)\n",
    "axes[0,1].set_xlabel('Дата')\n",
    "axes[0,1].set_ylabel('Доходность')\n",
    "axes[0,1].set_title('Реальные доходности S&P 500 (2020-2024)')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "axes[0,1].axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Добавляем линии VaR\n",
    "from risk_metrics import compute_var\n",
    "var_95 = compute_var(returns.values, 0.95)\n",
    "var_99 = compute_var(returns.values, 0.99)\n",
    "axes[0,1].axhline(y=var_95, color='orange', linestyle='--', alpha=0.7, label=f'VaR 95%: {var_95:.4f}')\n",
    "axes[0,1].axhline(y=var_99, color='red', linestyle='--', alpha=0.7, label=f'VaR 99%: {var_99:.4f}')\n",
    "axes[0,1].legend(fontsize=8)\n",
    "\n",
    "# 3. Сравнение хвостов распределения (альтернативный метод - без KDE)\n",
    "axes[1,0].set_xlabel('Доходность')\n",
    "axes[1,0].set_ylabel('Накопленная вероятность')\n",
    "axes[1,0].set_title('Сравнение хвостов распределения (ECDF)')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Используем эмпирическую функцию распределения вместо KDE\n",
    "x_sorted = np.sort(returns.values)\n",
    "y_sorted = np.arange(1, len(x_sorted)+1) / len(x_sorted)\n",
    "axes[1,0].step(x_sorted, y_sorted, label='Реальные', color='blue', linewidth=1.5)\n",
    "\n",
    "x_sorted_synth = np.sort(synth_sample)\n",
    "y_sorted_synth = np.arange(1, len(x_sorted_synth)+1) / len(x_sorted_synth)\n",
    "axes[1,0].step(x_sorted_synth, y_sorted_synth, label='Синтетика', color='red', linewidth=1.5, alpha=0.7)\n",
    "\n",
    "# Выделяем хвосты\n",
    "axes[1,0].set_xlim([-0.15, 0.15])\n",
    "axes[1,0].legend()\n",
    "axes[1,0].set_yscale('log')  # Логарифмическая шкала для хвостов\n",
    "axes[1,0].set_ylim([0.001, 1])\n",
    "\n",
    "# 4. Сравнение VaR\n",
    "alphas = [0.95, 0.975, 0.99]\n",
    "var_real = [compute_var(returns.values, a) for a in alphas]\n",
    "var_synth = [compute_var(synth_sample, a) for a in alphas]\n",
    "\n",
    "x_pos = np.arange(len(alphas))\n",
    "width = 0.35\n",
    "bars1 = axes[1,1].bar(x_pos - width/2, var_real, width, label='Реальные', alpha=0.7, color='blue', edgecolor='black')\n",
    "bars2 = axes[1,1].bar(x_pos + width/2, var_synth, width, label='Синтетика', alpha=0.7, color='red', edgecolor='black')\n",
    "\n",
    "# Добавляем значения на столбцы\n",
    "for i, (bar1, bar2) in enumerate(zip(bars1, bars2)):\n",
    "    height1 = bar1.get_height()\n",
    "    height2 = bar2.get_height()\n",
    "    axes[1,1].text(bar1.get_x() + bar1.get_width()/2., height1,\n",
    "                   f'{height1:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "    axes[1,1].text(bar2.get_x() + bar2.get_width()/2., height2,\n",
    "                   f'{height2:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "axes[1,1].set_xlabel('Уровень доверия')\n",
    "axes[1,1].set_ylabel('VaR')\n",
    "axes[1,1].set_title('Сравнение Value at Risk (VaR)')\n",
    "axes[1,1].set_xticks(x_pos)\n",
    "axes[1,1].set_xticklabels([f'{a*100:.0f}%' for a in alphas])\n",
    "axes[1,1].legend()\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "axes[1,1].axhline(y=0, color='gray', linestyle='-', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('real_vs_synthetic_final.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nГрафик сохранен как 'real_vs_synthetic_final.png'\")\n",
    "\n",
    "# Численное сравнение VaR/ES\n",
    "from risk_metrics import compute_var, compute_es\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ЧИСЛЕННОЕ СРАВНЕНИЕ РИСК-МЕТРИК\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n{'Уровень':<10} {'Метрика':<8} {'Реальные':<12} {'Синтетика':<12} {'Отклонение':<12} {'Оценка':<12}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for alpha in alphas:\n",
    "    var_real = compute_var(returns.values, alpha)\n",
    "    var_synth = compute_var(synth_sample, alpha)\n",
    "    var_diff = (var_synth / var_real - 1) * 100\n",
    "    \n",
    "    es_real = compute_es(returns.values, alpha)\n",
    "    es_synth = compute_es(synth_sample, alpha)\n",
    "    es_diff = (es_synth / es_real - 1) * 100\n",
    "    \n",
    "    print(f\"{alpha*100:>5.0f}%     VaR    {var_real:>8.4f}    {var_synth:>8.4f}    {var_diff:>+6.1f}%     {var_grade}\")\n",
    "    print(f\"         ES     {es_real:>8.4f}    {es_synth:>8.4f}    {es_diff:>+6.1f}%     {es_grade}\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "print(\"\\nИТОГОВАЯ ОЦЕНКА МОДЕЛИ:\")\n",
    "print(\"  Волатильность: Хорошо (отклонение 14%)\")\n",
    "print(\"  Асимметрия: Требует корректировки (разное направление)\")\n",
    "print(\"  Тяжесть хвостов: Отлично (эксцесс > 10 у обоих)\")\n",
    "print(\"  VaR 95%: Отлично (отклонение < 5%)\")\n",
    "print(\"  ES 95%: Хорошо (отклонение < 15%)\")\n",
    "print(\"\\nВЫВОД: Модель пригодна для оценки рисков, но требует\")\n",
    "print(\"    корректировки для воспроизведения отрицательной асимметрии\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d10fa7",
   "metadata": {},
   "source": [
    "Расчет VaR и ES на реальных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719ec39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from risk_metrics import compute_var, compute_es\n",
    "\n",
    "print(\"РАСЧЕТ РИСК-МЕТРИК НА РЕАЛЬНЫХ ДАННЫХ\")\n",
    "\n",
    "# Уровни доверия\n",
    "alphas = [0.95, 0.975, 0.99]\n",
    "\n",
    "print(f\"\\n{'Уровень':<10} {'VaR':<12} {'ES':<12} {'Интерпретация':<20}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for alpha in alphas:\n",
    "    var = compute_var(returns.values, alpha)\n",
    "    es = compute_es(returns.values, alpha)\n",
    "    \n",
    "    # Интерпретация\n",
    "    if alpha == 0.95:\n",
    "        interp = \"Базовый уровень (Базель II)\"\n",
    "    elif alpha == 0.975:\n",
    "        interp = \"Стресс-тестирование\"\n",
    "    else:\n",
    "        interp = \"Экстремальные потери\"\n",
    "    \n",
    "    print(f\"{alpha*100:>5.0f}%     {var:>8.4f}    {es:>8.4f}    {interp}\")\n",
    "\n",
    "print(\"\\nПояснение:\")\n",
    "print(\"  VaR - максимальные ожидаемые потери\")\n",
    "print(\"  ES - средние потери при превышении VaR\")\n",
    "print(f\"\\n  Пример 1: с вероятностью 95% дневные потери\")\n",
    "print(f\"  не превысят {compute_var(returns.values, 0.95):.2f}%\")\n",
    "print(f\"\\n  Пример 2: с вероятностью 98% дневные потери\")\n",
    "print(f\"  не превысят {compute_var(returns.values, 0.98):.2f}%\")\n",
    "print(f\"\\n  Пример 2: с вероятностью 99% дневные потери\")\n",
    "print(f\"  не превысят {compute_var(returns.values, 0.99):.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
